# AI Writer ğŸ–‹ï¸

A sleek desktop application for AI-assisted writing powered by **Ollama** and built with **PyQt5**. Let your local LLM continue your stories, articles, or documents seamlessly.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org)
[![PyQt5](https://img.shields.io/badge/PyQt5-5.15+-green.svg)](https://www.riverbankcomputing.com/software/pyqt/)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-orange.svg)](https://ollama.ai)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## âœ¨ Features

- **ğŸ¤– AI Text Completion** - Continue your writing with local LLM models via Ollama
- **ğŸ¨ Light/Dark Theme** - Toggle between beautiful light and dark modes
- **ğŸŒ¡ï¸ Temperature Control** - Adjust creativity vs. focus (0.0 - 2.0)
- **ğŸ“Š Token Limit** - Control response length (10 - 2000 tokens)
- **ğŸ“ Model Selection** - Choose from all your installed Ollama models
- **ğŸ’¾ Multiple Export Formats** - Save as .txt or .docx (Word)
- **ğŸ–¥ï¸ Modern UI** - Clean, responsive interface with sidebar controls

---

## ğŸ“‹ Requirements

### System Requirements
- **Python 3.8+**
- **Ollama** installed and running locally
- **Operating System**: Windows, macOS, or Linux

### Python Dependencies
```
PyQt5>=5.15.0
requests>=2.28.0
python-docx>=0.8.11  # Optional, for .docx support
```

---

## ğŸš€ Installation

### 1. Install Ollama

First, ensure Ollama is installed and running on your system:

**Windows/macOS:**
```bash
# Download from https://ollama.ai
# Then pull a model
ollama pull thewindmom/hermes-3-llama-3.1-8b
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull thewindmom/hermes-3-llama-3.1-8b
```

### 2. Clone the Repository

```bash
git clone [https://github.com/yourusername/ai-writer.git](https://github.com/Laszlobeer/AI-Writer.git)
cd ai-writer
```

### 3. Create Virtual Environment (Recommended)

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

### 4. Install Dependencies

```bash
pip install -r requirements.txt
```

Or install manually:
```bash
pip install PyQt5 requests python-docx
```

---

## ğŸ¯ Usage

### Starting the Application

```bash
python ai_writer.py
```

### Basic Workflow

1. **Select a Model** - Click the model dropdown and choose an installed Ollama model
2. **Write Your Text** - Start typing in the editor
3. **Position Cursor** - Place cursor where you want AI to continue
4. **Click Generate** - Press the âœ¨ Generate button or use keyboard shortcut
5. **Review & Edit** - AI completion will be inserted at cursor position
6. **Save Your Work** - Export as .txt or .docx

### Controls

| Control | Description |
|---------|-------------|
| ğŸŒ™/â˜€ï¸ | Toggle Light/Dark theme |
| ğŸ”„ | Refresh available models |
| âœ¨ Generate | Trigger AI completion |
| ğŸ“„ Save .txt | Export as text file |
| ğŸ“• Save .docx | Export as Word document |
| ğŸŒ¡ï¸ Temperature | Adjust creativity (left=focused, right=creative) |
| ğŸ“Š Token Limit | Set maximum response length |

---

## âš™ï¸ Configuration

### Default Settings

| Setting | Default Value | Description |
|---------|--------------|-------------|
| Temperature | 0.7 | Balance between creativity and coherence |
| Token Limit | 140 | Maximum tokens in AI response |
| Ollama URL | http://localhost:11434 | Local Ollama server endpoint |

### Customizing Settings

You can modify default values in the source code (`ai_writer.py`):

```python
# In ai_writer.py
OLLAMA_URL = "http://localhost:11434"
DEFAULT_TOKEN_LIMIT = 140
DEFAULT_TEMPERATURE = 0.7
```

### Temperature Guide

- **0.0 - 0.5** ğŸ¯ Focused, deterministic output
- **0.5 - 1.0** âš–ï¸ Balanced creativity and coherence
- **1.0 - 2.0** ğŸ¨ Highly creative, unpredictable output

---


---

## ğŸ–¼ï¸ Screenshots

### Light Mode
![Light Mode](screenshots/light_mode.png)

### Dark Mode
![Dark Mode](screenshots/dark_mode.png)



---

## ğŸ”§ Troubleshooting

### Ollama Connection Error
```
Cannot connect to Ollama. Is it running?
```
**Solution:** Ensure Ollama service is running:
```bash
ollama serve
```

### No Models Found
```
No models available
```
**Solution:** Pull a model:
```bash
ollama run thewindmom/hermes-3-llama-3.1-8b
```

### python-docx Not Available
```
install python-docx for .docx
```
**Solution:** Install the package:
```bash
pip install python-docx
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Code Style
- Follow PEP 8 guidelines
- Add comments for complex logic
- Test on multiple platforms

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai) - Local LLM infrastructure
- [PyQt5](https://www.riverbankcomputing.com/software/pyqt/) - GUI framework
- [python-docx](https://python-docx.readthedocs.io/) - Word document support

---



---


